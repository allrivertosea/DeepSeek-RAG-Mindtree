import streamlit as st
from mindtree_graph import retrieve_from_graph
from langchain_core.documents import Document
import requests
import json
from logger_config import logger


# ä½¿ç”¨HyDEè¿›è¡ŒæŸ¥è¯¢æ‰©å±•
def expand_query(query,uri,model):
    try:
        response = requests.post(uri, json={
            "model": model,
            "prompt": f"ä¸ºä»¥ä¸‹é—®é¢˜ç”Ÿæˆä¸€ä¸ªå‡è®¾æ€§ç­”æ¡ˆ: {query}",
            "stream": False
        }).json()
        return f"{query}\n{response.get('response', '')}"
    except Exception as e:
        st.error(f"æŸ¥è¯¢æ‰©å±•å¤±è´¥: {str(e)}")
        return query


# é«˜çº§æ£€ç´¢ç®¡é“
# è¯¥å‡½æ•°ä½¿ç”¨ BM25ã€FAISS å’Œ GraphRAG æ¥æ£€ç´¢ç›¸å…³æ–‡æ¡£ï¼Œå¹¶æ”¯æŒç¥ç»é‡æ–°æ’åº

def retrieve_documents(query, uri, model, chat_history=""):
    expanded_query = expand_query(f"{chat_history}\n{query}", uri, model) if st.session_state.enable_hyde else query
    
    # ä½¿ç”¨ BM25 + FAISS è¿›è¡Œæ–‡æ¡£æ£€ç´¢
    with st.spinner("æ­£åœ¨æ£€ç´¢ç›¸å…³æ–‡æ¡£..."):
        docs = st.session_state.retrieval_pipeline["ensemble"].invoke(expanded_query)
        logger.info(f"BM25 + FAISS æ£€ç´¢åˆ° {len(docs)} ç¯‡ç›¸å…³æ–‡æ¡£")

    # GraphRAG ç›¸å…³æ€§æ£€ç´¢
    if st.session_state.enable_graph_rag:
        graph_results = retrieve_from_graph(query, st.session_state.retrieval_pipeline["knowledge_graph"])
        
        # æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯
        logger.info(f"GraphRAG æ£€ç´¢åˆ° {len(graph_results)} ä¸ªç›¸å…³èŠ‚ç‚¹")
        st.write(f"ğŸ” GraphRAG æ£€ç´¢åˆ°çš„èŠ‚ç‚¹: {graph_results}")

        # ç¡®ä¿ GraphRAG ç»“æœçš„æ ¼å¼æ­£ç¡®
        graph_docs = [Document(page_content=node) for node in graph_results]
        # å¦‚æœ GraphRAG ç»“æœæœ‰æ•ˆï¼Œåˆ™åˆå¹¶åˆ°æ£€ç´¢ç»“æœä¸­
        if graph_docs:
            docs = graph_docs + docs  # åˆå¹¶ GraphRAG ç»“æœä¸ BM25 + FAISS ç»“æœ

    # ç¥ç»é‡æ–°æ’åº (å¦‚æœå¯ç”¨)
    if st.session_state.enable_reranking:
        pairs = [[query, doc.page_content] for doc in docs]  # é‡æ–°æ’åºæ—¶ä½¿ç”¨ `page_content`
        scores = st.session_state.retrieval_pipeline["reranker"].predict(pairs)

        # æŒ‰ç…§é‡æ–°æ’åºçš„å¾—åˆ†å¯¹æ–‡æ¡£è¿›è¡Œæ’åº
        ranked_docs = [doc for _, doc in sorted(zip(scores, docs), reverse=True)]
    else:
        ranked_docs = docs

    return ranked_docs[:st.session_state.max_contexts]  # æ ¹æ®æœ€å¤§ä¸Šä¸‹æ–‡æ•°è¿”å›ç»“æœ